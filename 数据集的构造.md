# 📚 数据集构造指南（Dataset Construction Guide）

> 本文档介绍了如何使用 **Easy Dataset（EDS）** 构造高质量的微调数据集，以及在 Web 安全领域任务中的数据构造思路与质量审查标准。

---

## 🧠 一、数据集构造思路

数据集是大语言模型（LLM）微调的核心。其质量直接决定了模型在目标任务中的表现。
本项目采用系统化的数据构造策略，确保数据的 **相关性、均衡性与高质量**：

1. **领域知识提取**

   * 从《白帽子讲 Web 安全》等专业书籍中提取结构化问答样本；
2. **前沿知识扩充**

   * 从最新论文中提取问题-答案对，涵盖 Web 安全研究新趋势：

     * 《The Hidden Risks of LLM-Generated Web Application Code》
     * 《WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks》
     * 《A Human Study of Cognitive Biases in Web Application Security》
3. **教师模型蒸馏（Knowledge Distillation）**

   * 使用 **DeepSeek R1 0528 满血版模型** 生成高质量问答与推理链（CoT）数据；
4. **多样性增强（GA：Genre-Audience 方法）**

   * 对样本从体裁与受众维度进行扩充，涵盖多种任务类型（解释、推理、漏洞分析等）；
5. **专家审校（Expert Review）**

   * 邀请 Web 安全领域专家对最终数据集进行质量评估与修订，确保专业性与一致性。

---

## 🧰 二、使用 Easy Dataset（EDS） 构造数据集

**Easy Dataset（EDS）** 是一款专为大语言模型数据集构造设计的工具，支持高效、结构化的数据生产与管理。

* 🏠 **GitHub**：[ConardLi/easy-dataset](https://github.com/ConardLi/easy-dataset)
* 📖 **官方文档**：[docs.easy-dataset.com](https://docs.easy-dataset.com/)
  （已被 **EMNLP** 收录）

### 💡 功能特点

* 可视化数据构造：支持多模板编辑、实时生成与预览
* 完全兼容 OpenAI / LLaMA / Qwen 等 LLM API 格式
* 自动清洗与去重机制，减少噪声数据
* 导出为 `json`、`jsonl`、`csv` 等多种格式

---

## ⚠️ 三、数据集质量控制要点

下列问题是导致微调失败的常见原因，构造过程中需重点规避：

| 问题类别        | 说明                                               |
| :---------- | :----------------------------------------------- |
| **数据量太小**   | 样本不足导致过拟合。领域任务建议 ≥ 1000 条（7B 模型起步），模型参数越大所需数据越多。 |
| **噪声数据多**   | 包含错别字、重复、乱码或错误标注，需清洗与规范化。                        |
| **样本偏差严重**  | 训练数据与真实应用分布差异过大，如正负样本不平衡。                        |
| **任务相关性不足** | 数据形式与目标任务不符，如问答任务混入叙述性新闻。                        |
| **数据多样性不足** | 指令、场景或特征维度单一，缺乏覆盖不同输入形式的样本。                      |

> ✅ **优先保证质量，而非数量。**
> 数据越多并不一定更好；低质量数据会放大模型误差。

---

## 🧩 四、数据构造步骤（EDS 实践）

### 1️⃣ 准备原始素材

* Web 安全书籍章节、论文、研究报告；
* 专家标注问答、漏洞场景说明。

### 2️⃣ 在 EDS 中创建任务

* 选择模板：`Instruction → Response`（Alpaca 格式）；
* 或 `Conversation → Messages`（ShareGPT 格式）；
* 导入素材文本，并配置指令生成策略。

### 3️⃣ 语料清洗与格式统一

* 去除冗余段落、HTML符号、重复问答；
* 对齐字段名（如 `instruction`、`input`、`output`）。

### 4️⃣ 教师模型蒸馏增强

* 调用 DeepSeek R1 生成高质量回答；
* 提取其 **推理链（Chain-of-Thought, CoT）**；
* 标注字段：

  ```json
  {
    "instruction": "解释XSS攻击的原理。",
    "output": "XSS是一种前端输入未过滤导致的跨站脚本漏洞...",
    "cot": "用户输入未进行转义 → 浏览器执行恶意JS → 数据泄露。"
  }
  ```

### 5️⃣ 多样性扩充（GA增强）

* 使用 Genre（任务类型） + Audience（目标受众）策略；
* 如面向开发者的技术问答、面向管理者的策略建议。

### 6️⃣ 专家人工复审

* 检查样本合理性、一致性与事实准确性；
* 对模糊或冲突样本进行修订或剔除。

---

## 🔍 五、数据集 Review 标准（专家审查环节）

| 审查维度        | 要求                                   |
| :---------- | :----------------------------------- |
| **事实一致性**   | 答案与文献事实一致，不得出现错误的漏洞类型、来源或样本量。        |
| **范围准确性**   | 答案内容不超出原文范围，不添加推断或假设信息。              |
| **问答对应性**   | 答案需直接回应问题，避免冗余或偏题内容。                 |
| **任务聚焦性**   | 保留与“数据集属性”相关的问题，剔除与模型方法无关内容。         |
| **关键信息完整性** | 明确时间、数据格式、标注一致性等指标。                  |
| **术语统一**    | 保持技术术语一致（如统一使用 “XSS” 而非 “跨站脚本攻击”）。   |
| **重复合并**    | 同类问题仅保留一个，避免冗余。                      |
| **定量明确化**   | 模糊表述需具体化（如“质量较高”→“标注一致率Kappa=0.85”）。 |

✅ **所有数据集均经 Web 安全专家人工 Review。**
